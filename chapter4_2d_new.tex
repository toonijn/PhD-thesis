% !TeX root = chapter4_2d_new.tex
\input{util.tex}
\startchapter{4}
\undefinedlabel{cha:c2}{2}
\undefinedlabel{cha:c3}{3}

\longchapter[New methods]{New methods for the \twoD time-independent Schrödinger equation}\label{cha:c4}

In chapter \ref{cha:c2} we have studied the constant perturbation methods. We have seen a brief history about these CP-methods, as well as, a thorough overview about how these methods can be implemented. The numerical examples illustrated the benefits and demonstrated the accuracy of the studied techniques.

Chapter \ref{cha:c3} was dedicated to the treatment of a recent method to solve the time-independent two-dimensional Schrödinger equation. This method aims to use the strengths of the constant perturbation methods for higher dimensional problems. This new method is promising, and we developed many improvements upon the original idea.

One of the unique powers of the CP-methods was their ability to not only compute low eigenvalues accurately, but even increase accuracy for higher eigenvalues. This is one of the few, if not the only, method which has this very desirable property for Sturm-Liouville problems. For two dimensions, this property did not translate cleanly. The method described in chapter \ref{cha:c3} tries to capture this by considering solutions of a one-dimensional Schrödinger problem in the $x$-direction. And a method for a coupled system of Schrödinger equations has been used in the $y$-direction. In theory this method is capable of computing any eigenvalue. In practice, this is not the case. Along the $x$-direction an eigenfunction is represented as a linear combination of basis functions. This basis is well-chosen, such that only a few number of functions are able to capture the true eigenfunctions sufficiently. Yet, as computers are finite, this basis has to be this as well. As eigenfunctions corresponding to higher eigenvalues will become more and more oscillatory, the chosen finite basis will no longer be able to express all necessary details.

That the basis is finite, thus, limits the accuracy for higher eigenvalues. Which negates one of the strongest benefits of the employed CP-methods. As such, we believe that the utopian method for the more-dimensional time-independent Schrödinger equation, is one which does not decrease in accuracy, as the higher eigenvalues are requested. Just like the CP-methods are for the one-dimensional case. Developing such a method will, most likely, require new and very complicated formulae.

For clarity, we did not develop such a perfect method. But in the last few years I've played with the idea... In section \ref{c4:sec_utopy} we will present some ideas for such a method. Some of which, someone, somewhere, may find inspirational.

More realistically, during our research into the method of Ixaru, we have found other research, also focussing upon the time-independent Schrödinger problem. These ideas and methods have inspired us to develop our own technique. The new methods we propose try to fix or mitigate some issues present in the other methods.

    {\color{red} To do: list other methods}

\section{Inspiration}

\subsection{A finite difference scheme}

\subsection{A semi-discrete method}\label{sec:c4_semi_discrete}

\section{A woven interpolation method}

In contrast to the previous methods, we propose a technique which is not necessarily restricted to cases where the domain is only a rectangle. So consider a finite domain $\Omega \subseteq \RR$ on which we are searching eigenvalues $E \in \RR$ and eigenfunctions $\psi: \Omega \to \RR$ such that for a given potential $V : \Omega \to \RR$ the following holds
\begin{equation}\label{equ:c4_schrodinger_equation_new_method}
    -\nabla^2 \psi + V(x, y) \psi = E \psi\text{.}
\end{equation}
Still, we impose homogenous Dirichlet boundary conditions, thus, $\psi(x, y) = 0$ for $(x, y) \in \Omega$.

The main idea underlying this method is that we want to represent the eigenfunctions $\psi$ efficiently. A fully discretized method may represent eigenfunctions as it's values on certain grid points. Our first attempt to develop a more continuous approximation of the eigenfunction used ideas from chapter \ref{cha:c3} and led to the creation of section \ref{sec:c4_semi_discrete}. Here we have chosen to approximate the eigenfunction as a linear combination of well-chosen basis functions on parallel lines throughout the domain. This led to a continuous approximation along one direction and a discrete approximation along the other direction of the domain.

\begin{figure}
    \begin{center}
        \includegraphics[width=.8\linewidth]{img/chapter4/the_method_grid.pdf}
        \caption{\label{fig:woven_method_grid} The grid}
    \end{center}
\end{figure}

In this new method we will bring this continuous approximation to both directions of the domain. For this, we place a grid over the domain $\Omega$, as can be seen in figure \ref{fig:woven_method_grid}. This grid need not be equidistant or square. When developing this new method we strived to allow for maximal flexibility, by avoiding as many restrictions on $\Omega$ as possible. This has as consequence that, because $\Omega$ does not have to be a rectangle, the number of intersections per grid line is not necessarily constant. Upon formulating and implementing this new method, this varying number of intersections is one example of some difficulties that arise by explicitly allowing more flexibility.

After placing the grid on $\Omega$, the next step is to approximate the unknown eigenfunction $\psi$ as a linear combination of basis functions on each of the grid lines. On the vertical line $x = x_i$, we denote these basis functions as $\beta_k^{(x_i)}(y)$, for each value of $k$. This yields the expression
$$
    \psi(x_i, y) = \sum_{k=0}^\infty c_k^{(x_i)} \beta_k^{(x_i)}(y) \text{.}
$$
For horizontal lines $y = y_j$, the basis functions $\beta_k^{(y_j)}(x)$ yield a similar expression
$$
    \psi(x, y_j) = \sum_{k=0}^\infty c_k^{(y_j)} \beta_k^{(y_j)}(x) \text{.}
$$

To ensure $\psi(x, y)$ is uniquely defined in each point in $\Omega$ we have to require that in each intersection point $(x_i, y_j)$, $\psi(x_i, y_j)$ has only one solution:
$$
    \psi(x_i, y_j) = \sum_{k=0}^\infty c_k^{(x_i)} \beta_k^{(x_i)}(y_j) = \sum_{k=0}^\infty c_k^{(y_j)} \beta_k^{(y_j)}(x_i)\text{.}
$$

Before deciding on which basis functions we should use, let us consider the Schrödinger equation \eqref{equ:c4_schrodinger_equation_new_method} on each intersection point $(x_i, y_j)$ with this new representation of $\psi$:
$$
    -\sum_{k=0}^\infty c_k^{(x_i)} \beta''^{(x_i)}_k(y_j) - \sum_{k=0}^\infty c_k^{(y_j)} \beta''^{(y_j)}_k(x_i) + (V(x_i, y_j) - E) \psi(x_i, y_j) = 0\text{.}
$$

This last formula suggest to chose $\beta_k^{(x_i)}$ and $\beta_k^{(y_j)}$, such that its second derivative contains, in a certain sense, $V(x_i, y_j)$. Together with the idea from chapter \ref{cha:c3} to use a one-dimensional Schrödinger equation, this leads us to propose $\beta_k^{(x_i)}$ and $\beta_k^{(y_j)}$ to be the ordered eigenfunctions which satisfy the one dimensional Schrödinger equation
$$
    -\beta_k''^{(x_i)}(y) + \frac{V(x_i, y)}{2}\beta_k^{(x_i)}(y) = \lambda_k^{(x_i)} \beta_k^{(x_i)}(y)
$$
with homogenous Dirichlet boundary conditions. The domain for this one-dimensional problem is the intersection of the vertical line $x = x_i$ and the two-dimensional domain $\Omega$. Similarly, for the horizontal line $y = y_j$, we propose $\beta_k^{(y_j)}(x)$ to be the eigenfunctions of
$$
    -\beta_k''^{(y_j)}(x) + \frac{V(x, y_j)}{2}\beta_k^{(y_j)}(x) = \lambda_k^{(y_j)} \beta_k^{(y_j)}(x)
$$
with homogenous Dirichlet boundary conditions, and as domain the intersection of $y = y_j$ and $\Omega$.

By choosing half the original potential in each of the approximations, in each intersection $(x_i, y_j)$, equation \eqref{equ:c4_schrodinger_equation_new_method} simplifies, and $V(x, y)$ disappears:
\begin{equation}\label{equ:c4_new_method_pre_matrix}
    \sum_{k=0}^\infty \lambda_k^{(x_i)} c_k^{(x_i)} \beta^{(x_i)}_k(y_j) + \sum_{k=0}^\infty \lambda_k^{(y_j)} c_k^{(y_j)} \beta_k^{(y_j)}(x_i) = E \psi(x_i, y_j) \text{.}  
\end{equation}

Notice that in this expression only $E$ (the eigenvalue) and $c_k^{x_i}$ and $c_k^{y_j}$ are unknown, as $\psi(x_i, y_j)$ depends linearly on $c_k^{x_i}$ and $c_k^{y_j}$. So, expression \eqref{equ:c4_new_method_pre_matrix} is, in fact, a linear eigenvalue-like problem.

{\color{red} To do: limit the infinite sums, and approximate as a matrix problem.}


\section{Some ideas for a utopian method}\label{c4:sec_utopy}

\stopchapter
